<h1 style="text-align: center">数据挖掘学习报告</h1>
<p style="text-align: center">stormlin 2017-06-07</p>

最近学习了数据挖掘常用的两种算法：FP-Growth 和 K-Means。现在把我的学习结果分享给大家。

以下是本文的目录，大家可以根据需要跳过一些章节：
<!-- TOC -->

- [1. FP-Growth](#1-fp-growth)
- [2. K-Means](#2-k-means)
    - [2.1 分类原理](#21-分类原理)
    - [2.2 步骤简介](#22-步骤简介)
- [3.Reference](#3reference)

<!-- /TOC -->

文中的引用以上标表示。

## 1. FP-Growth

在生活中，我们常常会遇到一些需要分析事物之间的关联性的场合。例如，在分析超市的销售数据时，我们可能会想知道，顾客在买牛奶的时候，还会买什么别的东西。还有数据挖掘领域里面著名的啤酒与尿布的故事<sup>R1</sup>。

要解决这些问题，我们就需要一种算法来帮我们寻找这些事务项之间的关联性。常用的**关联分析（Association Analysis）**算法有 Apriori 算法和 FP-Growth 算法。Apriori 算法的时空复杂度都比较高，现在已经不常用了，故本文略去对 Apriori 算法的介绍，专注于对 FP-Growth 的介绍与分析。

## 2. K-Means

在对数据进行了关联分析之后，有时候还需要对数据进行**聚簇分析（Clustering Analysis）**。聚类分析的算法较多，这里只介绍 K-Means 算法。这个算法的输入有数据集和分类数目 K；输出是分在 K 个簇中的数据项。

### 2.1 分类原理

1.  分类的方法主要是计算某个点与所有 K 个质心之间的欧几里得距离。计算两个 n 维点之间的欧几里得距离<sup>R4</sup>：
![二维欧几里得距离](./img/n维欧几里得距离.jpg)

    实用的计算方法：
    ```java
    private static double getEuclidDistance(Point a, Point b) {
        double result = 0;
        result += Math.pow(a.getX() - b.getX(), 2);
        result += Math.pow(a.getY() - b.getY(), 2);
        result += Math.pow(a.getZ() - b.getZ(), 2);
        return Math.sqrt(result);
    }
    ```

2.  计算质心的方法：在 K-Means 算法中，分类需要按照欧几里得距离最小的原则。但在实用的算法中，通常采用重心来代替质心：
    ```java
    private static Point getClusterCenter(List<Point> points) {
        if (points.size() == 0) {
            return null;
        }
        if (points.size() == 1) {
            return new Point(points.get(0).getX(), points.get(0).getY(), points.get(0).getZ());
        }
        double x = 0;
        double y = 0;
        double z = 0;
        for (Point point : points) {
            x += point.getX();
            y += point.getY();
            z += point.getZ();
        }
        x = x / points.size();
        y = y / points.size();
        z = z / points.size();
        return new Point(x, y, z);
    }
    ```

### 2.2 步骤简介

K-Means 算法是一种很好理解的算法，其步骤异常简单。

1.  用户提供输入数据集。数据集中的每一项都需要包含若干属性。如输入一个二维点集，那其中的一项就需要至少包含 X 和 Y 两个坐标；
2.  由用户指定初始质心或者由算法在输入的数据集中随机选取 K 个点作为初始质心；
3.  计算每一项到每一个质心之间的欧几里得距离；
4.  按照欧几里得距离最小的原则，把这些点分到 K 个簇中的某一个；
5.  重新计算 K 个簇中的质心（通常用计算重心代替）；
6.  如果质心与分类时使用的质心相同，则算法结束；否则就需要重复 2-6 步。

## 3.Reference

1.  http://canworksmart.com/diapers-beer-retail-predictive-analytics/
1.  http://www.tuicool.com/articles/VBBnie
2.  http://www.sohu.com/a/135368994_354986
4.  http://blog.csdn.net/tianlan_sharon/article/details/50904641